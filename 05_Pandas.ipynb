{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "The `numpy` module is excellent for numerical computations, but to handle missing data or arrays with mixed types takes more work. The `pandas` module is currently the most widely used tool for data manipulation, providing high-performance, easy-to-use data structures and advanced data analysis tools.\n",
    "\n",
    "In particular `pandas` features:\n",
    "\n",
    "* A fast and efficient \"DataFrame\" object for data manipulation with integrated indexing;\n",
    "* Tools for reading and writing data between in-memory data structures and different formats (CSV, Excel, SQL, HDF5);\n",
    "* Intelligent data alignment and integrated handling of missing data;\n",
    "* Intelligent label-based slicing, fancy indexing, and subsetting of large data sets;\n",
    "* Aggregating or transforming data with a powerful \"group-by\" engine; \n",
    "* High performance merging and joining of data sets;\n",
    "* Hierarchical axis indexing provides an intuitive way of working with high-dimensional data in a lower-dimensional data structure;\n",
    "* Time series-functionalities;\n",
    "* Highly optimized for performance, with critical code paths written in Cython or C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Series are completely equivalent to 1D array but with axis labels and the possibility to store heterogeneous elements. Of paramount importance are the time-series, used to define time evolutions of a phenomenon. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase as letters\n",
    "\n",
    "# Creating a series, accessing indexes, values and values by their index \n",
    "xs = Series(np.arange(10)*0.5, index=tuple(letters[:10]))\n",
    "print (xs,'\\n')\n",
    "print (xs.index,'\\n')\n",
    "# Values of the Series are actually a numpy array\n",
    "print (xs.values, type(xs.values),'\\n')\n",
    "print (xs['f'], xs.f, xs.h, '\\n')\n",
    "print (xs[['d', 'f', 'h']], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting elements and operations: same as numpy array\n",
    "print (xs[:3],'\\n')\n",
    "print (xs[7:], '\\n')\n",
    "print (xs[::3], '\\n')\n",
    "print (xs[xs>3], '\\n')\n",
    "print (np.exp(xs), '\\n')\n",
    "print (np.mean(xs), np.std(xs), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series can be created from python dictionary too.\n",
    "# Not that the elements can be whatever!\n",
    "d = {'b' : 1, 'a' : 'cat', 'c' : [2,3]}\n",
    "pd.Series(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference between Series and ndarray is that operations between Series automatically align the data based on label. Thus, you can write computations without giving consideration to whether the Series involved have the same labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(5), index=tuple(letters[:5]))\n",
    "s[1:] + s[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series\n",
    "\n",
    "Time series are very often used to profile the behaviour of a quantity as a function of time. Pandas as a special index for that, `DatetimeIndex`, that can be created e.g. with the function `pd.data_range()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to define a date, the datetime module is very useful\n",
    "import datetime as dt\n",
    "date = dt.date.today()\n",
    "date = dt.datetime(2018,11,19,14,45,10,15)\n",
    "print (date)\n",
    "\n",
    "# otherwise, several notations are interpreted too\n",
    "date = 'Nov 19 2018'\n",
    "date = '19/11/2018 14:45:00'\n",
    "print (date)\n",
    "\n",
    "days = pd.date_range(date, periods=7, freq='D')\n",
    "print (days)\n",
    "\n",
    "seconds = pd.date_range(date, periods=3600, freq='s')\n",
    "print (seconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the frequency strings, please see this [link](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases)\n",
    "\n",
    "\n",
    "Timestamped data is the most basic type of time series data that associates values with points in time. For pandas objects it means using the points in time.\n",
    "\n",
    "functions like `pd.to_datetime` can be used, for instance, when reading information as string from a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = pd.Timestamp(dt.datetime(2018, 11, 19))\n",
    "\n",
    "# internally it counts the nanoseconds from January 1st 19\n",
    "#tstamp = pd.Timestamp(dt.datetime(1970, 1, 1, 0, 0, 0, 1))\n",
    "print(tstamp.value)\n",
    "\n",
    "# when creating a timestamp the format can be explicitly passed\n",
    "print (pd.to_datetime('2010/11/12', format='%Y/%m/%d'))\n",
    "print (pd.to_datetime('12-11-2010 00:00', format='%d-%m-%Y %H:%M'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard series can be created and (range of) elements can be used as indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tseries = Series(np.random.normal(10, 1, len(days)), index=days)\n",
    "# Extracting elements\n",
    "print (tseries[0:4], '\\n')\n",
    "print (tseries['2018-11-19':'2018-11-21'], '\\n') # Note - includes end time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.to_datetime` can also be used to create a `DatetimeIndex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime([1, 2, 3], unit='D', origin=pd.Timestamp('1980-02-03'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "A pandas DataFrame is like a simple tabular spreadsheet. For future reference (or for people already familiar with R), a pandas DataFrame is very similar to the R DataFrame.\n",
    "\n",
    "Each column in a DataFrame is a Series object.\n",
    "\n",
    "The element can be whatever, missing data are dealt with too (as NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame creation\n",
    "\n",
    "A DataFrame can be created implicitly, with, e.g., a DatatimeIndex object as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries=10\n",
    "dates=pd.date_range('19/11/2018 14:45:00',freq='h', periods=entries)\n",
    "df = pd.DataFrame(np.random.randn(entries,4), index=dates, columns=['A','B','C','D'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by means of a dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    { 'A' : 1.,\n",
    "      'B' : pd.Timestamp('20130102'),\n",
    "      'C' : pd.Series(1,index=range(4),dtype='float32'),\n",
    "      'D' : np.arange(7,11),\n",
    "      'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "    }\n",
    "    )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "\n",
    "### Getting slices\n",
    "\n",
    "The following show how to get part of the DataFrame (i.e. not just the elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard and safe\n",
    "print (df['A'],'\\n')\n",
    "\n",
    "## equivalent but dangerous (imagine blank spaces in the name of the column..)\n",
    "print (df.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting rows by counting\n",
    "print (df[0:3])\n",
    "\n",
    "# or by index\n",
    "print (df[\"2018-11-19 14:45:00\":\"2018-11-19 16:45:00\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a cross section (part of the DataFrame) using a label\n",
    "df.loc[dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting on a multi-axis by label:\n",
    "df.loc[:,['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing label slicing, both endpoints are included:\n",
    "df.loc['2018-11-19 18:45:00':'2018-11-19 20:45:00',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting an individual element\n",
    "print (df.loc[dates[1],'A'])\n",
    "\n",
    "# equivalently\n",
    "print (df.at[dates[1],'A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select via the position of the passed integers:\n",
    "print (df.iloc[3],'\\n')\n",
    "\n",
    "# notation similar to numpy/python\n",
    "print (df.iloc[3:5,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting raws 1,2 and 4 for columns 0 and 2\n",
    "df.iloc[[1,2,4],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing rows explicitly\n",
    "print (df.iloc[1:3,:],'\\n')\n",
    "\n",
    "# slicing columns explicitly\n",
    "print (df.iloc[:,1:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting an individual element by position\n",
    "df.iloc[1,1]\n",
    "df.iat[1,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean index\n",
    "\n",
    "Very powerful way of filtering out data with certain features. Notation is very similar to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by a boolean condition on the values of a single column\n",
    "df[df['B'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting on the basis of boolean conditions applied to the whole DataFrame\n",
    "df[df>0]\n",
    "\n",
    "# a DataFrame with the same shape is returned, with NaN's where condition is not met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n",
    "\n",
    "Combination of selection and setting of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting values by label (same as by position)\n",
    "df.at[dates[0],'A'] = 0\n",
    "\n",
    "# setting and assigning a numpy array\n",
    "df.loc[:,'D'] = np.array([5] * len(df))\n",
    "\n",
    "# defining a brend new column\n",
    "df['E'] = np.arange(len(df))*0.5\n",
    "\n",
    "# defining a brend new column by means of a pd.Series: indexes must be the same!\n",
    "df['E prime'] = pd.Series(np.arange(len(df))*2, index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcos(theta):\n",
    "    theta = theta*(np.pi/180)\n",
    "    return np.cos(theta)\n",
    " \n",
    "df['cosine'] = pd.Series(df[\"E\"].apply(dcos), index=df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example of global setting\n",
    "df2=df.copy()\n",
    "df2[df2>0] = -df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping\n",
    "\n",
    "N.B.: dropping doesn't act permanently on the DataFrame, i.e. to get that do :\n",
    "```python\n",
    "df = df.drop(....)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping by column\n",
    "df.drop(['E prime'], axis=1)\n",
    "\n",
    "#which is equivalent to\n",
    "df.drop(columns=['E prime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping by raws\n",
    "# save and always working\n",
    "df.drop(df.index[[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something like df.drop('index_name') \n",
    "# would work but the type of index must be specificed, \n",
    "# in particular with DatetimeIndex\n",
    "df.drop(pd.to_datetime(\"2018-11-19 22:45:00\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "pandas primarily uses the value np.nan to represent missing data. It is by default not included in computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wNan = df[df>0]\n",
    "df_wNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping raws with at least a Nan\n",
    "df_wNan.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a mask\n",
    "df_wNan.isna()\n",
    "#df_wNan.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing data\n",
    "df_wNan.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill gaps forward or backward by propagating non-NA values forward or backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wNan.fillna(method='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "Here comes the most relevant advantage of DataFrame. Operations on columns are extremly fast, almost as fast as the actual operation between elements in a raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some statistics (mean() just as an example)\n",
    "# raws\n",
    "print (df.mean(axis=0),'\\n')\n",
    "# columns\n",
    "print (df.mean(axis=1),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global operations on columns\n",
    "df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax is as usual similar to that of numpy arrays\n",
    "df['A']+df['B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play it hard and load (in memory) a (relatively) large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"/Users/mzanetti/data/LEMMA2018/DT/raw/data_000636.txt\"\n",
    "data=pd.read_csv(file_name)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's know do some operations among (elements of) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one-liner killing it all\n",
    "data['timens']=data['TDC_MEAS']*25/30+data['BX_COUNTER']*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the old slooow way\n",
    "def conversion(data):\n",
    "    result=[]\n",
    "    for i in range(len(data)): \n",
    "        result.append(data.loc[data.index[i],'TDC_MEAS']*25/30.+data.loc[data.index[i],'BX_COUNTER']*25)\n",
    "    return result\n",
    "\n",
    "data['timens']=conversion(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n",
    "\n",
    "### Concat\n",
    "\n",
    "concatenation (adding raws) is straightforward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.DataFrame(np.random.randn(10, 4))\n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide it into pieaces raw-wise\n",
    "pieces = [rdf[:3], rdf[3:7], rdf[7:]]\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it back together\n",
    "pd.concat(pieces)\n",
    "\n",
    "# indexes can be ignored\n",
    "#pd.concat(pieces, ignore_index=True)\n",
    "\n",
    "# in case of dimension mismatch, Nan are added where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending a single raw (as a Series)\n",
    "s = rdf.iloc[3]\n",
    "rdf.append(s, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge/Join\n",
    "\n",
    "SQL like operations on table can be performed on DataFrames. This is all rather sophisticated, refer to the [doc](https://pandas.pydata.org/pandas-docs/stable/merging.html#merging) for more info/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
    "\n",
    "pd.merge(left,right,on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "* Splitting the data into groups based on some criteria\n",
    "* Applying a function to each group independently\n",
    "* Combining the results into a data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                    'B' : ['one', 'one', 'two', 'three',\n",
    "                           'two', 'two', 'one', 'three'],\n",
    "                    'C' : np.random.randn(8),\n",
    "                    'D' : np.random.randn(8)})\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and then applying the sum() \n",
    "# function to the resulting groups (effective only where number are there).\n",
    "gdf.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-indexing\n",
    "\n",
    "\n",
    "Hierarchical / Multi-level indexing allows sophisticated data analysis on higher dimensional data. In essence, it enables you to store and manipulate data with an arbitrary number of dimensions in lower dimensional data structures like Series (1d) and DataFrame (2d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = list(zip(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']))\n",
    "multi_index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "print (index,'\\n')\n",
    "\n",
    "s = pd.Series(np.random.randn(8), index=multi_index)\n",
    "print (s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it enables further features of the groupby method,\n",
    "# e.g. when group-by by multiple columns\n",
    "gdf.groupby(['A','B']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack() method “compresses” a level in the DataFrame’s columns\n",
    "gdf.groupby(['A','B']).sum().stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Just a preview, more on the next lab class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts.cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=pd.DataFrame(np.random.randn(1000, 4), index=ts.index,columns=['A', 'B', 'C', 'D'])\n",
    "df = df.cumsum()\n",
    "plt.figure(); df.plot(); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
